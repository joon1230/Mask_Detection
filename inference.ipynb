{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spiritual-criminal",
   "metadata": {},
   "source": [
    "#### Ensemble Log\n",
    "\n",
    "__43th__  __ensemble_top5__  \n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2500300_train_0.4_ver14_LowTrainRatio/epoch_15.pth  \n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2oversample_size_500300_loss_label_weight/epoch_20.pth  \n",
    "resnet34/resnet34_size224_oversampling/baseline_36.pth  \n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2oversample_size_400300_loss_label_weight_totaltwo/epoch_14.pth  \n",
    "Inception_resnet/inception_resnet_v2_batch32_size224/baseline_31.pth\n",
    "  \n",
    "<br></br> \n",
    "\n",
    "__46th__ __ensemble_top3__  \n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2500300_train_0.4_ver14_LowTrainRatio/epoch_15.pth  \n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2oversample_size_500300_loss_label_weight/epoch_20.pth  \n",
    "resnet34/resnet34_size224_oversampling/baseline_36.pth  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "__50th ensemble_top4__  \n",
    "EfficientNet_b4/<class 'torch.optim.adam.Adam'>/EfficientNet_b4500300_train_0.7_augmentation/epoch_12.pth  \n",
    "  \n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2400300_train_0.7_ver17/epoch_8.pth  \n",
    "\n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2500300_train_0.4_ver14_LowTrainRatio/epoch_15.pth  \n",
    "\n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2oversample_size_500300_loss_label_weight/epoch_20.pth\n",
    "\n",
    "\n",
    "\n",
    "__58th ensemble top6__\n",
    "\n",
    "EfficientNet_b4/<class 'torch.optim.adam.Adam'>/EfficientNet_b4500300_train_0.7_augmentation/epoch_12.pth  \n",
    "\n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2400300_train_0.7_ver17/epoch_8.pth  \n",
    "\n",
    "\n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2500300_train_0.4_ver14_LowTrainRatio/epoch_15.pth  \n",
    "\n",
    "EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2oversample_size_500300_loss_label_weight/epoch_20.pth\n",
    "\n",
    "resnet34/resnet34_size224_oversampling/baseline_36.pth  \n",
    "\n",
    "ResNet50/<class 'torch.optim.adam.Adam'>/ResNet50500300_train_0.8_ver16/epoch_3.pth\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "immediate-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Inference\n",
    "import Datasets\n",
    "import Models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-newfoundland",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "\n",
    "#### Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-excellence",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "#### 다양한 모델을 통한 앙상블 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Inference\n",
    "import Datasets\n",
    "import Models\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "## 47 76.9524% 0.6811\n",
    "model_1 = Inference.Inference(\n",
    "    model = Models.EfficientNet_b2(pretrained=False), \n",
    "    input_size = (400,300), \n",
    "    model_path = \"EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2400300_train_0.7_ver17/epoch_8.pth\",  \n",
    "    ensemble = True,\n",
    "    nick_name='th',\n",
    ")\n",
    "\n",
    "# 48 76.3492% 0.6342\n",
    "model_2 = Inference.Inference(\n",
    "    model = Models.EfficientNet_b7(pretrained=False), \n",
    "    input_size = (500,300), \n",
    "    model_path = \"EfficientNet_b7/<class 'torch.optim.adam.Adam'>/EfficientNet_b7500300_train_0.7_v2/epoch_3.pth\",  \n",
    "    ensemble = True,\n",
    "    nick_name='th',\n",
    ")\n",
    "\n",
    "# 28  75.7937%\t0.6955 \n",
    "model_3 = Inference.Inference(\n",
    "    model = Models.EfficientNet_b2(pretrained=False), \n",
    "    input_size = (500,300), \n",
    "    model_path = \"EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2oversample_size_500300_loss_label_weight/epoch_20.pth\",  \n",
    "    ensemble = True,\n",
    "    nick_name='th',\n",
    ")\n",
    "\n",
    "# 13 75.5900%\t0.6900\n",
    "model_4 = Inference.Inference(\n",
    "    model = Models.Resnet34(pretrained=False), \n",
    "    input_size = (224,224), \n",
    "    model_path = \"resnet34/resnet34_size224_oversampling/baseline_36.pth\",  \n",
    "    ensemble = True,\n",
    "    nick_name='th',\n",
    ")\n",
    "\n",
    "# 42 75.1111%\t0.7067\n",
    "model_5 = Inference.Inference(\n",
    "    model = Models.EfficientNet_b2(pretrained=False), \n",
    "    input_size = (500,300), \n",
    "    model_path = \"EfficientNet_b2/<class 'torch.optim.adam.Adam'>/EfficientNet_b2500300_train_0.4_ver14_LowTrainRatio/epoch_15.pth\",  \n",
    "    ensemble = True,\n",
    "    nick_name='th',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]\n",
    "\n",
    "results_dict = {}\n",
    "# models = [model_3, model_4]\n",
    "results = np.zeros((12600,18),dtype='float64')\n",
    "for m in models:\n",
    "    res = m.infer()\n",
    "    results += res\n",
    "    results_dict.update({m.model_path : res})\n",
    "    \n",
    "    print(end='\\n\\n')\n",
    "model_1 = model_1.submission.copy()\n",
    "submission = model_1.copy()\n",
    "\n",
    "res = [i.argmax() for i in results]\n",
    "submission['ans'] = res\n",
    "submission.to_csv('KingGobensemble.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-bangkok",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recognized-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference ResnNext/<class 'torch.optim.adam.Adam'>/ResnNext384384_scheduler/epoch_3.pth\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12600/12600 [03:45<00:00, 55.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import Inference\n",
    "import Datasets\n",
    "import Models\n",
    "import numpy as np\n",
    "\n",
    "model = Inference.Inference(\n",
    "    model = Models.ResNext(pretrained=True),\n",
    "    load_size = None,\n",
    "    input_size = (384,384), \n",
    "    model_path = \"ResnNext/<class 'torch.optim.adam.Adam'>/ResnNext384384_scheduler/epoch_3.pth\",  \n",
    "    ensemble = True,\n",
    "    nick_name='100th_',\n",
    ")\n",
    "\n",
    "r = model.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "linear-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ResnNext384384_scheduler_epoch_3.npy',r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-edgar",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "#### Inference TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contained-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference EfficientNet_b4/<class 'torch.optim.adam.Adam'>/EfficientNet_b4400384_scheduler/epoch_9.pth\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12600/12600 [05:44<00:00, 36.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference EfficientNet_b4/<class 'torch.optim.adam.Adam'>/EfficientNet_b4400384_scheduler/epoch_9.pth\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12600/12600 [05:44<00:00, 36.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/data/eval/TTA_EfficientNet_b4400384_schedulerepoch_9.csv saved\n"
     ]
    }
   ],
   "source": [
    "import Inference\n",
    "import Datasets\n",
    "import Models\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "input_size = (384,384)\n",
    "transform = Datasets.albumentation(size=input_size,\n",
    "                                       use_randcrop=True, use_center_crop=False, use_randomreisze_crop=False,\n",
    "                                       use_filp=True, use_rotate=True, use_blur=False,\n",
    "                                       use_noise=False, use_normalize=True, use_CLAHE=False,\n",
    "                                       use_invert=False, use_equalize=False, use_posterize=False,\n",
    "                                       use_soloarize=False, ues_jitter=False, use_Brightness=False,\n",
    "                                       use_Gamma=False, use_brightcontrast=False, use_cutout=False,\n",
    "                                       use_totensor=True\n",
    "                                       )\n",
    "\n",
    "\n",
    "model = Inference.Inference(\n",
    "    model = Models.EfficientNet_b4(pretrained=False),\n",
    "    load_size = None,\n",
    "    input_size = (384,384), \n",
    "    model_path = \"EfficientNet_b4/<class 'torch.optim.adam.Adam'>/EfficientNet_b4400384_scheduler/epoch_9.pth\",  \n",
    "    ensemble = True,\n",
    "    transform = transform,\n",
    "    nick_name='TTA_'\n",
    ")\n",
    "res, results = model.TTA()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
